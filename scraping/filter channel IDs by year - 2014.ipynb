{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8357d18",
   "metadata": {},
   "source": [
    "# Read channle IDs then search on it on json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d025021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from csv import reader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54495266",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "url = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\combinded for comments (filtered)\\comments filter by year(based on comment year Not main video)\\comments_data_{}.csv\".format(year)\n",
    "\n",
    "\n",
    "channels_ids = pd.read_csv(url, usecols=['snippet.topLevelComment.snippet.authorChannelId.value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27fe6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_ids = list(channels_ids['snippet.topLevelComment.snippet.authorChannelId.value'])\n",
    "channels_ids = set(channels_ids)\n",
    "channels_ids = list(channels_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35cd7a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36833"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(channels_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76c491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare files in a dir with a list then copy the target to the destination:\n",
    "\n",
    "for ii in range(1, 25):\n",
    "    \n",
    "\n",
    "    start = time.time()\n",
    "    path = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info\\channels info for commenters - {}\".format(ii)\n",
    "    source = os.listdir(path)\n",
    "    destination = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\{}\\{}\".format(year, ii)\n",
    "\n",
    "    i = 0            \n",
    "    for file in source:\n",
    "        i+=1\n",
    "        if i % 500 == 0: print('file no:', i, 'in folder',ii)\n",
    "        if file.split('.')[0] in channels_ids:\n",
    "            shutil.copy(path + '/'+file, destination)\n",
    "            channels_ids.remove(file.split('.')[0])\n",
    "    end = time.time()\n",
    "    print(\"time in minuts:\", (end - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd6d5c",
   "metadata": {},
   "source": [
    "# See if IDs not obtainied data for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6a659f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of channels we have info for:  36,823\n"
     ]
    }
   ],
   "source": [
    "# read all json files in folder and subfolder:\n",
    "path_to_json = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2014\"\n",
    "names = []\n",
    "for root, dirs, files in os.walk(path_to_json):\n",
    "    for name in files:\n",
    "        if name.endswith((\".json\")):\n",
    "            names.append(name.split('.')[0])\n",
    "            full_path = os.path.join(root, name)\n",
    "names = set(names)\n",
    "names = list(names)\n",
    "print('Count of channels we have info for: ', f\"{len(names):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a55afb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73656"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = channels_ids + names\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a8f14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = pd.DataFrame(all_ids, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0f391d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = all_ids.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7098fb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0b8d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids.to_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\2014_channels_ids.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6876cb",
   "metadata": {},
   "source": [
    "# Reading JSON files and combine them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8588e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6823"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read josn files and make a list with json files\n",
    "\n",
    "folder_no = 2\n",
    "path_to_json = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2014\\{}\".format(folder_no)\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "json_files;  \n",
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bac6abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 (500, 39) folder no: 2\n",
      "1000 (1000, 43) folder no: 2\n",
      "1500 (1500, 45) folder no: 2\n",
      "2000 (2000, 45) folder no: 2\n",
      "2500 (2500, 46) folder no: 2\n",
      "3000 (3000, 48) folder no: 2\n",
      "3500 (3500, 48) folder no: 2\n",
      "4000 (4000, 48) folder no: 2\n",
      "4500 (4500, 48) folder no: 2\n",
      "5000 (5000, 49) folder no: 2\n",
      "5500 (5500, 53) folder no: 2\n",
      "6000 (6000, 53) folder no: 2\n",
      "6500 (6500, 53) folder no: 2\n",
      "elapsed time: 1.545898727575938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6823, 53)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame with all json files:\n",
    "df = pd.DataFrame()\n",
    "start = time.time()\n",
    "i=0\n",
    "for file in json_files:\n",
    "    file_path = path_to_json + '/' + file\n",
    "    with open(file_path) as data_file:\n",
    "        i +=1\n",
    "        data = json.load(data_file)\n",
    "        df = df.append(pd.json_normalize(data))\n",
    "        if i % 500 == 0: print(i, df.shape, \"folder no:\", folder_no)\n",
    "end = time.time()\n",
    "print('elapsed time:',(end-start)/60)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17ce0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns.drop(list(df.filter(regex='localizations')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c3f4268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6823, 41)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e5698e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2014\\folder {}.csv\".format(folder_no), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed3bea",
   "metadata": {},
   "source": [
    "# Read combined files for each folder and make 1 CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12b060fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read josn files and make a list with json files\n",
    "# (make 1 change)\n",
    "\n",
    "path_to_csv = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2014\"\n",
    "csv_files = [pos_csv for pos_csv in os.listdir(path_to_csv) if pos_csv.endswith('.csv')]\n",
    "csv_files;  \n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cfe83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36823, 41)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in csv_files:\n",
    "    temp_df = pd.read_csv(path_to_csv + '/' + file)\n",
    "    df = df.append(temp_df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3058891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2014\\channles_info_2014.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6466e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
