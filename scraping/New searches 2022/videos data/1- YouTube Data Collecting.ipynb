{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e2517b",
   "metadata": {},
   "source": [
    "# Collect Data from Youtube using API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fbb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from csv import reader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f88ce3",
   "metadata": {},
   "source": [
    "# Check if there is any duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "id": "3fad3b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 1680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read youtube videos we have data for (usind video ID as file name)\n",
    "path_to_csv = r'C:\\Users\\Administrator\\AH case\\YouTube\\SNA-AH-Case-YouTube\\scraping\\New searches 2022\\searches results\\cleaned'\n",
    "csv_files = [pos_csv for pos_csv in os.listdir(path_to_csv) if pos_csv.endswith('.csv')]\n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5faa911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13886, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with the data we already have to prevent scrape it again \n",
    "# that because if the scraping stopped without finishing.\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in csv_files:\n",
    "    df = pd.read_csv(path_to_csv+\"/\"+filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cbaa6d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame dataframe have all data we alrady have and make sure there is no duplicate in it\n",
    "frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df9cdb",
   "metadata": {},
   "source": [
    "#  Collect data from youtube for videos using video ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84165bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YTstats:\n",
    "    '''\n",
    "    this class takes api_key and video id\n",
    "    then obtain data for the video\n",
    "    '''\n",
    "  \n",
    "    def __init__(self, api_key, video_id):\n",
    "        self.api_key = api_key\n",
    "        self.video_id = video_id\n",
    "        self.video_statistics = None\n",
    "  \n",
    "    def get_video_statistics(self):\n",
    "        '''\n",
    "        recieve data from youtube with URL have the video_id and API key\n",
    "        '''\n",
    "        url = f'https://www.googleapis.com/youtube/v3/videos?id={self.video_id}&key={self.api_key}&part=snippet,contentDetails,statistics,status'\n",
    "        json_url = requests.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "  \n",
    "        try:\n",
    "        # we need just the items from the json reply\n",
    "            data = data[\"items\"]#[0][\"statistics\"]\n",
    "        except:\n",
    "            data = None\n",
    "  \n",
    "        self.video_statistics = data\n",
    "        return data\n",
    "  \n",
    "    def dump(self):\n",
    "        '''\n",
    "        save the file with the data or print \"nothing happend\" it we have reply with no data\n",
    "        '''        \n",
    "    \n",
    "        if self.video_statistics is None:\n",
    "            print('nothing happend')\n",
    "            return \n",
    "  \n",
    "        video_title = self.video_id\n",
    "        #video_title = video_title.replace(\" \", \"_\")\n",
    "  \n",
    "        # generate a json file with all the statistics data of the youtube video\n",
    "        file_name = video_title + '.json'\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(self.video_statistics, f, indent=4)\n",
    "        print('file dumped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498514d1",
   "metadata": {},
   "source": [
    "# <a id='Obtaining'></a>  Obtaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2247,
   "id": "599c8dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'431- amber heard e johnny depp agressAo.csv'"
      ]
     },
     "execution_count": 2247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file url and folder url:\n",
    "\n",
    "file_name = s\n",
    "\n",
    "path = r\"C:\\Users\\Administrator\\AH case\\YouTube\\SNA-AH-Case-YouTube\\scraping\\New searches 2022\\searches results\\cleaned/\"\n",
    "\n",
    "file_url = path + file_name\n",
    "folder_url = \"./\" + str(file_url.split('/')[-1:]).split('.')[0][2:] + \"/\"\n",
    "if not os.path.isdir(folder_url):\n",
    "    os.makedirs(folder_url)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2248,
   "id": "b91ddb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, '431- amber heard e johnny depp agressAo.csv')"
      ]
     },
     "execution_count": 2248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data from youtube file and extratc video code for each and make a list of the videos code:\n",
    "\n",
    "# read dat for the same file we just dropped duplicate from:\n",
    "address = file_url\n",
    "Amber_Heard = pd.read_csv(address)\n",
    "Amber_Heard = Amber_Heard.melt().drop('variable',axis=1).rename({'value':'id'},axis=1)\n",
    "Amber_Heard = list(Amber_Heard['id']) # make a list with IDs we will obtain data from\n",
    "len(Amber_Heard), s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2249,
   "id": "e6f306c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3weKpH1mcd0', 'NgkeomkNJHE', 'rCEfxUic50o']"
      ]
     },
     "execution_count": 2249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amber_Heard[:3] #first 3 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2250,
   "id": "21b95554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3weKpH1mcd0\n",
      "ids remain:  6\n",
      "file dumped\n",
      "rCEfxUic50o\n",
      "ids remain:  5\n",
      "file dumped\n",
      "AqLJXrquPOM\n",
      "ids remain:  4\n",
      "file dumped\n",
      "FFUZ1dEJqLA\n",
      "ids remain:  3\n",
      "file dumped\n",
      "NgkeomkNJHE\n",
      "ids remain:  2\n",
      "file dumped\n",
      "WCS7p3CtLXc\n",
      "ids remain:  1\n",
      "file dumped\n",
      "rBU3p3KPKPk\n",
      "ids remain:  0\n",
      "file dumped\n"
     ]
    }
   ],
   "source": [
    "# recive data using API and save it on PC\n",
    "\n",
    "API_KEY = \"AIzaSyA-0KfpLK04NpQN1XghxhSlzG-WkC3DHLs\"\n",
    "API_KEY2 = \"AIzaSyCQHI5RSbHoKGh6sPPnnOywja7qLS6TXnA\"\n",
    "API_KEY3 = \"AIzaSyBcoNKqXd-bQ--bsLwKplkdHkGdKPtaa_8\"\n",
    "\n",
    "# read IDs form list to obtaining data:\n",
    "while len(Amber_Heard) != 0:\n",
    "    \n",
    "    for video in Amber_Heard:\n",
    "        print(video)\n",
    "        yt = YTstats(API_KEY, video)\n",
    "        yt.get_video_statistics()\n",
    "        Amber_Heard.remove(video)\n",
    "        print('ids remain: ', len(Amber_Heard))\n",
    "        yt.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33a2e3",
   "metadata": {},
   "source": [
    "#  read and save JSON files collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2251,
   "id": "c385ff26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Files moved ..\n"
     ]
    }
   ],
   "source": [
    "# move files to the named folder\n",
    "path_to_json = r'C:\\Users\\Administrator\\AH case\\YouTube\\SNA-AH-Case-YouTube\\scraping\\New searches 2022\\videos data'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "print(len(json_files))\n",
    "for file in json_files:\n",
    "    shutil.move(path_to_json+'\\\\'+file, path_to_json+'\\\\'+folder_url.split('/')[1])\n",
    "print(\"Files moved ..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2252,
   "id": "48db546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read josn files and make a list with json files\n",
    "# (make 1 change)\n",
    "\n",
    "path_to_json = folder_url\n",
    "\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "json_files;  \n",
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2253,
   "id": "2f5b4d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 46)"
      ]
     },
     "execution_count": 2253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame with all json files:\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for file in json_files:\n",
    "    file_path = path_to_json + file\n",
    "    with open(file_path) as data_file:    \n",
    "        data = json.load(data_file)\n",
    "        df = df.append(pd.json_normalize(data))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2254,
   "id": "c0d64e51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>etag</th>\n",
       "      <th>id</th>\n",
       "      <th>snippet.publishedAt</th>\n",
       "      <th>snippet.channelId</th>\n",
       "      <th>snippet.title</th>\n",
       "      <th>snippet.description</th>\n",
       "      <th>snippet.thumbnails.default.url</th>\n",
       "      <th>snippet.thumbnails.default.width</th>\n",
       "      <th>snippet.thumbnails.default.height</th>\n",
       "      <th>...</th>\n",
       "      <th>status.privacyStatus</th>\n",
       "      <th>status.license</th>\n",
       "      <th>status.embeddable</th>\n",
       "      <th>status.publicStatsViewable</th>\n",
       "      <th>status.madeForKids</th>\n",
       "      <th>statistics.viewCount</th>\n",
       "      <th>statistics.likeCount</th>\n",
       "      <th>statistics.favoriteCount</th>\n",
       "      <th>statistics.commentCount</th>\n",
       "      <th>snippet.defaultAudioLanguage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube#video</td>\n",
       "      <td>-DuMVgJ2KyzPB-XlhMWT-Vibafw</td>\n",
       "      <td>3weKpH1mcd0</td>\n",
       "      <td>2016-05-28T02:33:45Z</td>\n",
       "      <td>UCGU3WWVQQwxIB9fm4bRQqIA</td>\n",
       "      <td>Divórcio entre Johnny Depp e Amber Heard e pos...</td>\n",
       "      <td>Fala galera, estamos de volta com o Canal Só C...</td>\n",
       "      <td>https://i.ytimg.com/vi/3weKpH1mcd0/default.jpg</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>youtube</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3247</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube#video</td>\n",
       "      <td>lg6Z7MdKFcs7ZOXdqficnq53i1c</td>\n",
       "      <td>AqLJXrquPOM</td>\n",
       "      <td>2021-03-19T01:27:21Z</td>\n",
       "      <td>UCOF63gcrmnwDl3ttpx4d5fg</td>\n",
       "      <td>JOHNNY DEPP AGREDIDO PELA AMBER HEARD | JUSTIÇ...</td>\n",
       "      <td>No assuntos do momento de hoje vamos falar sob...</td>\n",
       "      <td>https://i.ytimg.com/vi/AqLJXrquPOM/default.jpg</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>youtube</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>537</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            kind                         etag           id  \\\n",
       "0  youtube#video  -DuMVgJ2KyzPB-XlhMWT-Vibafw  3weKpH1mcd0   \n",
       "0  youtube#video  lg6Z7MdKFcs7ZOXdqficnq53i1c  AqLJXrquPOM   \n",
       "\n",
       "    snippet.publishedAt         snippet.channelId  \\\n",
       "0  2016-05-28T02:33:45Z  UCGU3WWVQQwxIB9fm4bRQqIA   \n",
       "0  2021-03-19T01:27:21Z  UCOF63gcrmnwDl3ttpx4d5fg   \n",
       "\n",
       "                                       snippet.title  \\\n",
       "0  Divórcio entre Johnny Depp e Amber Heard e pos...   \n",
       "0  JOHNNY DEPP AGREDIDO PELA AMBER HEARD | JUSTIÇ...   \n",
       "\n",
       "                                 snippet.description  \\\n",
       "0  Fala galera, estamos de volta com o Canal Só C...   \n",
       "0  No assuntos do momento de hoje vamos falar sob...   \n",
       "\n",
       "                   snippet.thumbnails.default.url  \\\n",
       "0  https://i.ytimg.com/vi/3weKpH1mcd0/default.jpg   \n",
       "0  https://i.ytimg.com/vi/AqLJXrquPOM/default.jpg   \n",
       "\n",
       "   snippet.thumbnails.default.width  snippet.thumbnails.default.height  ...  \\\n",
       "0                               120                                 90  ...   \n",
       "0                               120                                 90  ...   \n",
       "\n",
       "  status.privacyStatus  status.license  status.embeddable  \\\n",
       "0               public         youtube               True   \n",
       "0               public         youtube               True   \n",
       "\n",
       "  status.publicStatsViewable  status.madeForKids  statistics.viewCount  \\\n",
       "0                       True               False                  3247   \n",
       "0                       True               False                   537   \n",
       "\n",
       "  statistics.likeCount  statistics.favoriteCount  statistics.commentCount  \\\n",
       "0                   87                         0                       49   \n",
       "0                   54                         0                        9   \n",
       "\n",
       "  snippet.defaultAudioLanguage  \n",
       "0                          NaN  \n",
       "0                           pt  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 2254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2255,
   "id": "4aa88ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this dataframe with the search name as csv file:\n",
    "\n",
    "save_csv_url = r\"C:\\Users\\Administrator\\AH case\\YouTube\\SNA-AH-Case-YouTube\\scraping\\New searches 2022\\videos details/{} --scraped.csv\".format(path_to_json.split('/')[1])\n",
    "df.to_csv(save_csv_url, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb88ad",
   "metadata": {},
   "source": [
    "# save channels IDs to collect channels info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2256,
   "id": "cc034e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels count before adding:  13743\n",
      "channels count after adding:  13750\n"
     ]
    }
   ],
   "source": [
    "# make new df with channels IDs:\n",
    "new_channels_id_df = pd.DataFrame(df['snippet.channelId'])\n",
    "\n",
    "# for the same batch read channels we have then add the news:\n",
    "channel_id_file_url = r'C:\\Users\\Administrator\\AH case\\YouTube\\SNA-AH-Case-YouTube\\scraping\\all_channels_ids.csv'\n",
    "channel_id_df = pd.read_csv(channel_id_file_url)\n",
    "print(\"channels count before adding: \", channel_id_df.shape[0])\n",
    "# append the two dfs together and update the file to have the new IDs\n",
    "total_channels_ids = new_channels_id_df['snippet.channelId'].append(channel_id_df['id'], ignore_index=True)\n",
    "total_channels_ids = pd.DataFrame(total_channels_ids, columns=['id'])\n",
    "total_channels_ids.to_csv(channel_id_file_url, index=None )\n",
    "print(\"channels count after adding: \", total_channels_ids.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e8d04",
   "metadata": {},
   "source": [
    "# [Go to Obtaining](#Obtaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755238c",
   "metadata": {},
   "source": [
    "# Combining all searches results in one file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2260,
   "id": "f2406208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 2260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_csv = r'C:\\Users\\Administrator\\AH case\\YouTube\\SNA-AH-Case-YouTube\\scraping\\New searches 2022\\videos details'\n",
    "csv_files = [pos_csv for pos_csv in os.listdir(path_to_csv) if pos_csv.endswith('.csv')]\n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2261,
   "id": "d97d03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- amber heard eve barlow --scraped.csv\n",
      "10- amber heard admits hitting johnny depp --scraped.csv\n",
      "100- amber heard hollywood --scraped.csv\n",
      "101- amber heard hollywood movies --scraped.csv\n",
      "102- amber heard actress --scraped.csv\n",
      "103- amber heard sexuality --scraped.csv\n",
      "104- amber heard life --scraped.csv\n",
      "105- amber heard fairfax --scraped.csv\n",
      "106- amber heard makeup --scraped.csv\n",
      "107- amber heard firmen --scraped.csv\n",
      "108- amber heard gagged --scraped.csv\n",
      "109- amber heard alert --scraped.csv\n",
      "11- amber heard twitter johnny depp --scraped.csv\n",
      "110- amber heard lawyer --scraped.csv\n",
      "111- amber heard adam waldman --scraped.csv\n",
      "112- amber heard russian --scraped.csv\n",
      "113- amber heard united nations --scraped.csv\n",
      "114- amber heard human rights --scraped.csv\n",
      "115- amber heard heartless --scraped.csv\n",
      "116- amber heard gets what she deserves --scraped.csv\n",
      "117- amber heard dog --scraped.csv\n",
      "118- amber heard rape --scraped.csv\n",
      "119- amber heard husband --scraped.csv\n",
      "12- amber heard defamation suit --scraped.csv\n",
      "120- amber heard husband now --scraped.csv\n",
      "121- amber heard husband beater --scraped.csv\n",
      "122- Amber Heard Jason Momoa --scraped.csv\n",
      "123- Amber Heard Audio --scraped.csv\n",
      "124- Amber Heard Beautiful --scraped.csv\n",
      "125- Amber Heard Fat --scraped.csv\n",
      "126- Amber Heard Actress Activist --scraped.csv\n",
      "127- Amber Heard Innocent --scraped.csv\n",
      "128- Amber Heard Talent --scraped.csv\n",
      "129- Amber Heard Slut --scraped.csv\n",
      "13- amber heard leaving aquaman --scraped.csv\n",
      "130- Amber Heard Bots --scraped.csv\n",
      "131- Amber Heard Kidnap --scraped.csv\n",
      "132- Amber Heard Testify --scraped.csv\n",
      "133- Amber Heard Court --scraped.csv\n",
      "134- Amber Heard Analyst --scraped.csv\n",
      "135- Amber Heard Body Language --scraped.csv\n",
      "136- Amber Heard Lie --scraped.csv\n",
      "137- Amber Heard Marriage --scraped.csv\n",
      "138- Amber Heard Spokesperson --scraped.csv\n",
      "139- Amber Heard Director --scraped.csv\n",
      "14- amber heard arrested for domestic violence --scraped.csv\n",
      "140- Amber Heard Actor --scraped.csv\n",
      "141- Amber Heard Weinstein --scraped.csv\n",
      "142- Amber Heard BBC --scraped.csv\n",
      "143- Amber Heard Thrive --scraped.csv\n",
      "144- Amber Heard Bisexual --scraped.csv\n",
      "145- Amber Heard Sister --scraped.csv\n",
      "146- Amber Heard Brandon --scraped.csv\n",
      "147- Amber Heard Truth --scraped.csv\n",
      "148- Amber Heard True --scraped.csv\n",
      "149- Amber Heard Honest --scraped.csv\n",
      "15- amber heard arrested 2009 --scraped.csv\n",
      "150- Amber Heard Leak --scraped.csv\n",
      "151- Amber Heard Woman --scraped.csv\n",
      "152- Amber Heard Film --scraped.csv\n",
      "153- Amber Heard Prejudice --scraped.csv\n",
      "154- Amber Heard Evidence --scraped.csv\n",
      "155- Amber Heard Proof --scraped.csv\n",
      "156- Amber Heard Report --scraped.csv\n",
      "157- Amber Heard Feminist --scraped.csv\n",
      "158- Amber Heard Australia --scraped.csv\n",
      "159- Amber Heard LAPD --scraped.csv\n",
      "16- johnny depp amber heard affaire --scraped.csv\n",
      "160- Amber Heard FBI --scraped.csv\n",
      "161- Amber Heard Police --scraped.csv\n",
      "162- Amber Heard Cop --scraped.csv\n",
      "163- Amber Heard Activist --scraped.csv\n",
      "164- Amber Heard Speaker --scraped.csv\n",
      "165- Amber Heard Assistant --scraped.csv\n",
      "166- Amber Heard Ex Wife --scraped.csv\n",
      "167- Amber Heard Miss Me --scraped.csv\n",
      "168- Amber Heard Assault --scraped.csv\n",
      "169- Amber Heard London --scraped.csv\n",
      "17- amber heard beaten --scraped.csv\n",
      "170- Amber Heard Restraining Order --scraped.csv\n",
      "171- Amber Heard Phone --scraped.csv\n",
      "172- Amber Heard Joke --scraped.csv\n",
      "173- Amber Heard Choke --scraped.csv\n",
      "174- Amber Heard Damages --scraped.csv\n",
      "175- Amber Heard Sexy --scraped.csv\n",
      "176- Amber Heard Hot --scraped.csv\n",
      "177- Amber Heard Call --scraped.csv\n",
      "178- Amber Heard 911 --scraped.csv\n",
      "179- Amber Heard Terrible --scraped.csv\n",
      "18- amber heard being crazy --scraped.csv\n",
      "180- Amber Heard Wrong --scraped.csv\n",
      "181- Amber Heard The Informers --scraped.csv\n",
      "182- Amber Heard Drive Angry --scraped.csv\n",
      "183- Amber Heard Justice League --scraped.csv\n",
      "184- Amber Heard Booed --scraped.csv\n",
      "185- Amber Heard Documentary --scraped.csv\n",
      "186- Amber Heard Over --scraped.csv\n",
      "187- Amber Heard Speaks --scraped.csv\n",
      "188- Amber Heard Wins --scraped.csv\n",
      "189- Amber Heard Sentenced --scraped.csv\n",
      "19- amber heard change --scraped.csv\n",
      "190- Amber Heard Magic Mike --scraped.csv\n",
      "191- Amber Heard Rum Diary --scraped.csv\n",
      "192- Amber Heard Virginia --scraped.csv\n",
      "193- Amber Heard Wanted --scraped.csv\n",
      "194- Amber Heard Flirting --scraped.csv\n",
      "195- Amber Heard Story --scraped.csv\n",
      "196- Amber Heard Case --scraped.csv\n",
      "197- Amber Heard Timeline --scraped.csv\n",
      "198- Amber Heard Warned --scraped.csv\n",
      "199- Amber Heard Danger --scraped.csv\n",
      "2- amber heard go to hell --scraped.csv\n",
      "20- amber heard death --scraped.csv\n",
      "200- Amber Heard Libel --scraped.csv\n",
      "201- Amber Heard Celebrities --scraped.csv\n",
      "202- Amber Heard Wife Beater --scraped.csv\n",
      "203- Amber Heard Begs --scraped.csv\n",
      "204- Amber Heard Trouble --scraped.csv\n",
      "205- Amber Heard Career --scraped.csv\n",
      "206- Amber Heard Wife --scraped.csv\n",
      "207- Amber Heard Apology --scraped.csv\n",
      "208- Amber Heard Quit --scraped.csv\n",
      "209- Amber Heard Behind Bars --scraped.csv\n",
      "21- amber heard fuck --scraped.csv\n",
      "210- Amber Heard Reputation --scraped.csv\n",
      "211- Amber Heard Shut Up --scraped.csv\n",
      "212- Amber Heard Finger --scraped.csv\n",
      "213- Amber Heard Loses --scraped.csv\n",
      "214- Amber Heard Fashion --scraped.csv\n",
      "215- Amber Heard Fit --scraped.csv\n",
      "216- Amber Heard Healthy --scraped.csv\n",
      "217- Amber Heard Fans --scraped.csv\n",
      "218- Amber Heard Hope --scraped.csv\n",
      "219- Amber Heard Espaniol --scraped.csv\n",
      "22- amber heard go die --scraped.csv\n",
      "220- Amber Heard Caso --scraped.csv\n",
      "221- Amber Heard Nicole Kidman --scraped.csv\n",
      "222- Amber Heard Reacts --scraped.csv\n",
      "223- Amber Heard Working --scraped.csv\n",
      "224- Amber Heard Work --scraped.csv\n",
      "225- Amber Heard Judge --scraped.csv\n",
      "226- Amber Heard Dismissed --scraped.csv\n",
      "227- Amber Heard Replaced --scraped.csv\n",
      "228- Amber Heard Legal --scraped.csv\n",
      "229- Amber Heard Hoax --scraped.csv\n",
      "23- amber heard jailforamberheard --scraped.csv\n",
      "230- Amber Heard Dossier --scraped.csv\n",
      "231- Amber Heard Message --scraped.csv\n",
      "232- Amber Heard Call Out --scraped.csv\n",
      "233- Amber Heard Subpoena --scraped.csv\n",
      "234- Amber Heard She Did --scraped.csv\n",
      "235- Amber Heard Media --scraped.csv\n",
      "236- Amber Heard Drugs --scraped.csv\n",
      "237-Amber Heard Exposed --scraped.csv\n",
      "238- Amber Heard Done --scraped.csv\n",
      "239- Amber Heard Film --scraped.csv\n",
      "24- amber heard kill amber --scraped.csv\n",
      "240- Amber Heard Happened --scraped.csv\n",
      "241- Amber Heard Analysis --scraped.csv\n",
      "242- Amber Heard Review --scraped.csv\n",
      "243- Amber Heard Fake --scraped.csv\n",
      "244- Amber Heard Paint --scraped.csv\n",
      "245- Amber Heard Wounds --scraped.csv\n",
      "246- Amber Heard Refugees --scraped.csv\n",
      "247- Amber Heard Mexico --scraped.csv\n",
      "248- Amber Heard Destroyed --scraped.csv\n",
      "249- Amber Heard Wrecked --scraped.csv\n",
      "25- amber heard threw a vodka bottle --scraped.csv\n",
      "250- Amber Heard Father --scraped.csv\n",
      "251- Amber Heard Huge --scraped.csv\n",
      "252- Amber Heard Criminal --scraped.csv\n",
      "253- Amber Heard Disney --scraped.csv\n",
      "254- Amber Heard Friends --scraped.csv\n",
      "255- Amber Heard Family --scraped.csv\n",
      "256- Amber Heard Divorce --scraped.csv\n",
      "257- Amber Heard Lying --scraped.csv\n",
      "258- Amber Heard Defending --scraped.csv\n",
      "259- Amber Heard Relationship --scraped.csv\n",
      "26- amber heard no one will believe you --scraped.csv\n",
      "260- Amber Heard Star --scraped.csv\n",
      "261- Amber Heard Responds --scraped.csv\n",
      "262- Amber Heard American --scraped.csv\n",
      "263- Amber Heard Flops --scraped.csv\n",
      "264- Amber Heard Busted --scraped.csv\n",
      "265- Amber Heard Movie Roles --scraped.csv\n",
      "266- Amber Heard Daily Mail --scraped.csv\n",
      "267- Amber Heard Remember --scraped.csv\n",
      "268- Amber Heard Hit --scraped.csv\n",
      "269- Amber Heard Love --scraped.csv\n",
      "27- amber heard petition --scraped.csv\n",
      "270- Amber Heard Parents --scraped.csv\n",
      "271- Amber Heard Times Up --scraped.csv\n",
      "272- Amber Heard Producer --scraped.csv\n",
      "273- Amber Heard Support --scraped.csv\n",
      "274- Amber Heard Revenge --scraped.csv\n",
      "275- Amber Heard Personality --scraped.csv\n",
      "276- Amber Heard Canceled --scraped.csv\n",
      "277- Amber Heard Update --scraped.csv\n",
      "278- Amber Heard Deposition --scraped.csv\n",
      "279- Amber Heard Women --scraped.csv\n",
      "28 -amber heard shit --scraped.csv\n",
      "280- Amber Heard Empowerment --scraped.csv\n",
      "281- Amber Heard Paris --scraped.csv\n",
      "282- Amber Heard Equality --scraped.csv\n",
      "283- Amber Heard Women's Rights --scraped.csv\n",
      "284- Amber Heard Gay --scraped.csv\n",
      "285- Amber Heard Lesbian --scraped.csv\n",
      "286- Amber Heard Investigating --scraped.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287- Amber Heard Threatens --scraped.csv\n",
      "288- Amber Heard Team --scraped.csv\n",
      "289- Amber Heard Character --scraped.csv\n",
      "29- amber heard stupid --scraped.csv\n",
      "290- Amber Heard Ambassador --scraped.csv\n",
      "291- Amber Heard Film Festival --scraped.csv\n",
      "292- Amber Heard Quit --scraped.csv\n",
      "293- Amber Heard Believe --scraped.csv\n",
      "294- Amber Heard Rejects --scraped.csv\n",
      "295- Amber Heard Claims --scraped.csv\n",
      "296- Amber Heard Trolls --scraped.csv\n",
      "297- Amber Heard Lost Work --scraped.csv\n",
      "298- Amber Heard Loss --scraped.csv\n",
      "299- Amber Heard Kind --scraped.csv\n",
      "3- amber heard surviving and adapting --scraped.csv\n",
      "30- to death amber heard --scraped.csv\n",
      "300- Amber Heard Social Good --scraped.csv\n",
      "301- Amber Heard Facts --scraped.csv\n",
      "302- Amber Heard Paid --scraped.csv\n",
      "303- Amber Heard Dismiss --scraped.csv\n",
      "304- Amber Heard Talk --scraped.csv\n",
      "305- Amber Heard Power --scraped.csv\n",
      "306- Amber Heard Rights --scraped.csv\n",
      "307- Amber Heard Causes --scraped.csv\n",
      "308- Amber Heard Scene --scraped.csv\n",
      "309- Amber Heard Happy --scraped.csv\n",
      "31- amber heard they won't believe you --scraped.csv\n",
      "310- Amber Heard Science --scraped.csv\n",
      "311- Amber Heard Hero --scraped.csv\n",
      "312- Amber Heard Superhero --scraped.csv\n",
      "313- Amber Heard Children --scraped.csv\n",
      "314- Amber Heard Staff --scraped.csv\n",
      "315- Amber Heard Bodyguards --scraped.csv\n",
      "316- Amber Heard Penthouse --scraped.csv\n",
      "317- Amber Heard Fame --scraped.csv\n",
      "318- Amber Heard Climber --scraped.csv\n",
      "319- Amber Heard Bombshell --scraped.csv\n",
      "32- amber heard whor --scraped.csv\n",
      "320- Amber Heard Afraid --scraped.csv\n",
      "321- Amber Heard Incredible --scraped.csv\n",
      "322- Amber Heart Top 10 --scraped.csv\n",
      "323- Amber Laura Heard --scraped.csv\n",
      "324- Amber Heard Late Show --scraped.csv\n",
      "325- Amber Heard Stunts --scraped.csv\n",
      "326- Amber Heard Music --scraped.csv\n",
      "327- Amber Heard Atheist --scraped.csv\n",
      "328- Amber Heard Catholic --scraped.csv\n",
      "329- Amber Heard Devil --scraped.csv\n",
      "33- amber heard violent --scraped.csv\n",
      "330- Amber Heard Show --scraped.csv\n",
      "331- Amber Heard Tonight --scraped.csv\n",
      "332- Amber Heard Girl --scraped.csv\n",
      "333- Amber Heard Adorable --scraped.csv\n",
      "334- Amber Heard Island --scraped.csv\n",
      "335- Amber Heard Press --scraped.csv\n",
      "336- Amber Heard Events --scraped.csv\n",
      "337- Amber Heard Entertainment --scraped.csv\n",
      "338- Amber Heard Glamour --scraped.csv\n",
      "339- Amber Heard Goals --scraped.csv\n",
      "34- amber heard tugging --scraped.csv\n",
      "340- Amber Heard Backstage --scraped.csv\n",
      "341- Amber Heard Project --scraped.csv\n",
      "342- Amber Heard Prank --scraped.csv\n",
      "343- Amber Heard Liam Hemsworth --scraped.csv\n",
      "344- Amber Heard Harrison Ford --scraped.csv\n",
      "345- Amber Heard Kevin Costner --scraped.csv\n",
      "346- Amber Heard Nicole Kidman --scraped.csv\n",
      "347- Amber Heard Angelina Jolie --scraped.csv\n",
      "348- Amber Heard Nicolas Cage --scraped.csv\n",
      "349- Amber Heard Sex --scraped.csv\n",
      "35- amber heard stupid ass --scraped.csv\n",
      "350- Amber Heard Blames --scraped.csv\n",
      "351- Amber Heard Drunk --scraped.csv\n",
      "352- Amber Heard Funny --scraped.csv\n",
      "353- Amber Heard Cute --scraped.csv\n",
      "354- Amber Heard Prize --scraped.csv\n",
      "355- Amber Heard Robotics --scraped.csv\n",
      "356- Amber Heard Magazine --scraped.csv\n",
      "357- Amber Heard Weekly --scraped.csv\n",
      "358- Amber Heard World --scraped.csv\n",
      "359- Amber Heard Premier --scraped.csv\n",
      "36- amber heard 50 million --scraped.csv\n",
      "360- Amber Heard Inspire --scraped.csv\n",
      "361- Amber Heard Laugh --scraped.csv\n",
      "362- Amber Heard Behind the Scene --scraped.csv\n",
      "363- Amber Heard Actors --scraped.csv\n",
      "364- Amber Heard AquaMera --scraped.csv\n",
      "365- Amber Heard Instagram --scraped.csv\n",
      "366- Amber Heard Worth It --scraped.csv\n",
      "367- Amber Heard Strong --scraped.csv\n",
      "368- Amber Heard Cheated --scraped.csv\n",
      "369- Amber Heard Emails --scraped.csv\n",
      "37- amber heard because she is a woman --scraped.csv\n",
      "370- Amber Heard Cam --scraped.csv\n",
      "371- Amber Heard Workout --scraped.csv\n",
      "372- Amber Heard Showed Off --scraped.csv\n",
      "373- Amber Heard Sorry --scraped.csv\n",
      "374- Amber Heard Defends --scraped.csv\n",
      "375- Amber Heard Evil --scraped.csv\n",
      "376- Amber Heard HBO --scraped.csv\n",
      "377- Amber Heard Marvel --scraped.csv\n",
      "378- Amber Heard Comics --scraped.csv\n",
      "379- Amber Heard Witness --scraped.csv\n",
      "38- amber heard boycottamber --scraped.csv\n",
      "380- Amber Heard Legend --scraped.csv\n",
      "381- Amber Heard Red Carpet --scraped.csv\n",
      "382- Amber Heard Los Angeles --scraped.csv\n",
      "383- Amber Heard Times --scraped.csv\n",
      "384- Amber Heard PI --scraped.csv\n",
      "385- Amber Heard Amazing --scraped.csv\n",
      "386- Amber Heard Perfect --scraped.csv\n",
      "387- Amber Heard Gorgeous --scraped.csv\n",
      "388- Amber Heard Beauty --scraped.csv\n",
      "389- Amber Heard Talented --scraped.csv\n",
      "39- amber heard bullshit --scraped.csv\n",
      "390- Amber Heard Awesome --scraped.csv\n",
      "391- Amber Heard Intelligent --scraped.csv\n",
      "392- Amber Heard Smart --scraped.csv\n",
      "393- Amber Heard LGBT --scraped.csv\n",
      "394- Amber Heard Iconic --scraped.csv\n",
      "395- Amber Heard Heart --scraped.csv\n",
      "396- Amber Heard Pretty --scraped.csv\n",
      "397- Amber Heard Camera --scraped.csv\n",
      "398- Amber Heard Success --scraped.csv\n",
      "399- Amber Heard Respect --scraped.csv\n",
      "4- amber heard emilia clarke aquaman --scraped.csv\n",
      "40- amber heard burn --scraped.csv\n",
      "400- Amber Heard Commercial --scraped.csv\n",
      "401- Amber Heard Playlist --scraped.csv\n",
      "402- Amber Heard Car --scraped.csv\n",
      "403- Amber Heard Top Gear --scraped.csv\n",
      "404- Amber Heard Best --scraped.csv\n",
      "405- Amber Heard Tribute --scraped.csv\n",
      "406- Amber Heard Cast --scraped.csv\n",
      "407- Amber Heard Never Back Down --scraped.csv\n",
      "408- Amber Heard Training --scraped.csv\n",
      "409- Amber Heard Fitness --scraped.csv\n",
      "41- amber heard change --scraped.csv\n",
      "410- Amber Heard Shorts --scraped.csv\n",
      "411- Amber Heard Ignores --scraped.csv\n",
      "412- Amber Heard Comic Con --scraped.csv\n",
      "413- Amber Heard Events --scraped.csv\n",
      "414- Amber Heard Variety --scraped.csv\n",
      "415- Amber Heard Mocks --scraped.csv\n",
      "416- Amber Heard Broken --scraped.csv\n",
      "417- Amber Heard Attractive --scraped.csv\n",
      "418- Amber Heard Clip --scraped.csv\n",
      "419- Amber Heard Footage --scraped.csv\n",
      "42- amber heard fake victim --scraped.csv\n",
      "420- Amber Heard Ruin --scraped.csv\n",
      "421- Amber Heard MovieClips --scraped.csv\n",
      "422- Amber Heard Explains --scraped.csv\n",
      "423- Amber Heard Network --scraped.csv\n",
      "424- Amber Heard Times --scraped.csv\n",
      "425- Amber Heard For --scraped.csv\n",
      "426- Amber Heard Fear --scraped.csv\n",
      "427- Amber Heard Dies --scraped.csv\n",
      "428- Amber Heard Guilt --scraped.csv\n",
      "429- Amber Heard Affair --scraped.csv\n",
      "43- amber heard exposingamberheard --scraped.csv\n",
      "430- Amber Heard Danny Devito --scraped.csv\n",
      "431- amber heard e johnny depp agressAo --scraped.csv\n",
      "44- amber heard felony --scraped.csv\n",
      "45- amber heard fireamber --scraped.csv\n",
      "46- amber heard petition --scraped.csv\n",
      "47- amber heard prison --scraped.csv\n",
      "48- amber heard punched --scraped.csv\n",
      "49- remove amber heard --scraped.csv\n",
      "5- amber heard girlfriend --scraped.csv\n",
      "50- amber heard scammer --scraped.csv\n",
      "51- amber heard gold digger --scraped.csv\n",
      "52- amber heard fraud --scraped.csv\n",
      "53- amber heard justice --scraped.csv\n",
      "54- amber heard is over --scraped.csv\n",
      "55- amber heard accountable --scraped.csv\n",
      "56- amber heard mentoo --scraped.csv\n",
      "57- amber heard metoo --scraped.csv\n",
      "58- amber heard thesun --scraped.csv\n",
      "59- amber heard --scraped.csv\n",
      "6- amber heard abuser --scraped.csv\n",
      "60- amber heard minamata --scraped.csv\n",
      "61- amber heard release minamata --scraped.csv\n",
      "62- amber heard city of lies --scraped.csv\n",
      "63- amber heard dior --scraped.csv\n",
      "64- amber heard new year --scraped.csv\n",
      "65- amber heard we stand with johnny depp --scraped.csv\n",
      "66- amber heard no johnny no pirates --scraped.csv\n",
      "67- amber heard johnny depp is innocent --scraped.csv\n",
      "68- amber heard boycott aquaman --scraped.csv\n",
      "69- amber heard abuse has no gender --scraped.csv\n",
      "7- amber heard texts --scraped.csv\n",
      "70- amber heard signing autographs --scraped.csv\n",
      "71- amber heard animaniacs --scraped.csv\n",
      "72- amber heard life --scraped.csv\n",
      "73- amber heard fight --scraped.csv\n",
      "74- amber heard homie --scraped.csv\n",
      "75- amber heard saying she hit johnny depp --scraped.csv\n",
      "76- amber heard saying no one will believe you --scraped.csv\n",
      "77- amber heard says no one will believe johnny depp --scraped.csv\n",
      "78- amber heard saying she donated money --scraped.csv\n",
      "79- amber heard people --scraped.csv\n",
      "8- amber heard trial --scraped.csv\n",
      "80- amber heard pooped on johnny depp's bed --scraped.csv\n",
      "81- amber heard psychopath --scraped.csv\n",
      "82- amber heard wrong --scraped.csv\n",
      "83- amber heard look --scraped.csv\n",
      "84- amber heard never --scraped.csv\n",
      "85- amber heard paid --scraped.csv\n",
      "86- amber heard away --scraped.csv\n",
      "87- johnny depp amber heard thanksgiving --scraped.csv\n",
      "88- amber heard talks about johnny depp --scraped.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89- amber heard says no one will believe johnny depp --scraped.csv\n",
      "9- Amber Heard Liar --scraped.csv\n",
      "90- amber heard is no body --scraped.csv\n",
      "91- amber heard votes --scraped.csv\n",
      "92- amber heard omg --scraped.csv\n",
      "93- amber heard facebook --scraped.csv\n",
      "94 -amber heard accusations --scraped.csv\n",
      "95- amber heard james franco --scraped.csv\n",
      "96- amber heard simping --scraped.csv\n",
      "97- amber heard bruises --scraped.csv\n",
      "98- amber heard aclu --scraped.csv\n",
      "99- amber heard model --scraped.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13750, 51)"
      ]
     },
     "execution_count": 2261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "\n",
    "for filename in csv_files:\n",
    "    df = pd.read_csv(path_to_csv+\"/\"+filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    print(filename)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2264,
   "id": "fbee21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_csv(r\"C:\\Users\\Administrator\\AH case\\YouTube\\SNA-AH-Case-YouTube\\scraping\\New searches 2022\\videos details\\all_vid_data_13750v.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24367f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
