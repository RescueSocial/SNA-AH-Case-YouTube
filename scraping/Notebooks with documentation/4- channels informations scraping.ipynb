{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a85169",
   "metadata": {},
   "source": [
    "# Obtaining channels infos by channel ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc42768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from csv import reader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ec81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YTstats:\n",
    "    '''\n",
    "    this class takes api_key and channel id\n",
    "    then obtain infor for the channel\n",
    "    '''    \n",
    "  \n",
    "    def __init__(self, api_key, channel_id):\n",
    "        self.api_key = api_key\n",
    "        self.channel_id = channel_id\n",
    "        self.video_statistics = None\n",
    "  \n",
    "    def get_video_statistics(self):\n",
    "        url = f'https://youtube.googleapis.com/youtube/v3/channels?part=snippet&part=contentDetails&part=brandingSettings&part=contentOwnerDetails&part=id&part=localizations&part=statistics&part=status&part=topicDetails&id={self.channel_id}&maxResults=200&key={self.api_key}'\n",
    "        json_url = requests.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "        nextPageToken = data.get(\"nextPageToken\")\n",
    "        \n",
    "        i = 0\n",
    "        a = ''\n",
    "        if nextPageToken:\n",
    "            while nextPageToken != a:\n",
    "                a = nextPageToken\n",
    "                i += 1\n",
    "                url = f'https://youtube.googleapis.com/youtube/v3/channels?part=snippet&part=contentDetails&part=brandingSettings&part=contentOwnerDetails&part=id&part=localizations&part=statistics&part=status&part=topicDetails&id={self.channel_id}&maxResults=200&key={self.api_key}&pageToken={nextPageToken}'\n",
    "                json_url = requests.get(url)\n",
    "                data1 = json.loads(json_url.text)\n",
    "                nextPageToken = data1.get(\"nextPageToken\")\n",
    "                data['items'] = data['items'] + data1['items']\n",
    "                \n",
    "                if nextPageToken is None:\n",
    "                    break\n",
    "                print('page number:', i+1)\n",
    "              #  print(nextPageToken, len(data['items']))\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            data = data[\"items\"]#[0][\"statistics\"]\n",
    "        except:\n",
    "            data = None\n",
    "  \n",
    "        self.video_statistics = data\n",
    "        return data\n",
    "  \n",
    "    def dump(self):\n",
    "        if self.video_statistics is None:\n",
    "            print('________________nothing happend________________')\n",
    "            return \n",
    "  \n",
    "        video_title = self.channel_id\n",
    "        video_title = video_title.replace(\" \", \"_\")\n",
    "  \n",
    "        # generate a json file with all the statistics data of the youtube video\n",
    "        file_name = video_title + '.json'\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(self.video_statistics, f, indent=4)\n",
    "        print('file dumped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdacb0a",
   "metadata": {},
   "source": [
    "# make sure we will not obtainig channels we already have info for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9525f783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read channel IDs for channels we want to obtain:\n",
    "channels_id_new = pd.read_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\2018_channels_ids.csv\")\n",
    "channels_id_list_new = set(channels_id_new['id'])\n",
    "#channels_id_list_new = set(channels_id_list_new)\n",
    "channels_id_list_new= list(channels_id_list_new)\n",
    "f\"{len(channels_id_list_new):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all json files in folder and subfolder:\n",
    "path_to_json = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2021\"\n",
    "names = []\n",
    "for root, dirs, files in os.walk(path_to_json):\n",
    "    for name in files:\n",
    "        if name.endswith((\".json\")):\n",
    "            names.append(name.split('.')[0])\n",
    "            full_path = os.path.join(root, name)\n",
    "names = set(names)\n",
    "names = list(names)\n",
    "print('Count of channels we have info for: ', f\"{len(names):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6884ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No duplicates in our list of channels:\", len(names) == len(set(names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b9b4f3",
   "metadata": {},
   "source": [
    "# make a new list with data we don't have info for it:\n",
    "print('Total channels count BEFORE remove duplicates: ', f\"{len(channels_id_list_new):,}\")\n",
    "channels_id = (names)+ (channels_id_list_new)\n",
    "channels_id = pd.DataFrame(channels_id, columns=['id'])\n",
    "channels_id = channels_id.drop_duplicates(keep=False)\n",
    "print('Total channels count AFTER  remove duplicates: ', f\"{len(channels_id):,}\")\n",
    "print('Removed count: ', f\"{len(channels_id_list_new)-len(channels_id):,}\")\n",
    "channels_id = list(channels_id['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fd3c6",
   "metadata": {},
   "source": [
    "# obtaining Data for CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bd47196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_id = channels_id_list_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "be26a9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{len(channels_id):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2e5e16b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-26 13:48:46.422648\n",
      "nan\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 84\n",
      "Channels scraped this run: 1\n",
      "UCc6FbVpW4_ba_Gl2Xbc_KJA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 83\n",
      "Channels scraped this run: 2\n",
      "UCYIgJpdxNXaY6_FwcWqPyxQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 82\n",
      "Channels scraped this run: 3\n",
      "UC7n-ZIwYaQJtC9_pdAsxRBQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 81\n",
      "Channels scraped this run: 4\n",
      "UC5cln9be3fKI9JrGSw2RHQg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 80\n",
      "Channels scraped this run: 5\n",
      "UCfggsnHVry9E4DthLzfMNKQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 79\n",
      "Channels scraped this run: 6\n",
      "UCh7m6cIata6Y_8If48DecsQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 78\n",
      "Channels scraped this run: 7\n",
      "UC3uzi4g7O4MMQvPVCRjogbg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 77\n",
      "Channels scraped this run: 8\n",
      "UCeFVrQNgIPdr7x0SErskGVg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 76\n",
      "Channels scraped this run: 9\n",
      "UCXLTc1OMnfq7JB7uhVIq1oQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 75\n",
      "Channels scraped this run: 10\n",
      "UCHlg8Qw2UbhHsa-qOZlJVCA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 74\n",
      "Channels scraped this run: 11\n",
      "UCm0VlFR35nKw3Blt3o_gzkg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 73\n",
      "Channels scraped this run: 12\n",
      "UCfePw9nIZgGGCKxp2sWM6SQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 72\n",
      "Channels scraped this run: 13\n",
      "UCoRzCNsGDhbRyJsxIAFe5xA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 71\n",
      "Channels scraped this run: 14\n",
      "UCepfglXLgDYKfc7a2hE9O5A\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 70\n",
      "Channels scraped this run: 15\n",
      "UCKhxyc9xidngp_-Snw7M2GQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 69\n",
      "Channels scraped this run: 16\n",
      "UCnc-XCFcesEJ_wfZnzUTW5Q\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 68\n",
      "Channels scraped this run: 17\n",
      "UCDPueMA-8zpwbwbsPVxyXiA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 67\n",
      "Channels scraped this run: 18\n",
      "UCV1CcOsLMf_LwOo88OX1IDQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 66\n",
      "Channels scraped this run: 19\n",
      "UCGQaKpVnbcF7jp3Wtx2P9eg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 65\n",
      "Channels scraped this run: 20\n",
      "UCY3I7zRNoL6sxaSHGIF3csQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 64\n",
      "Channels scraped this run: 21\n",
      "UC96lI7ouGiVaj2a1Unu74Sw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 63\n",
      "Channels scraped this run: 22\n",
      "UCL1Q8KsxxcXxUCy7Doiliyw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 62\n",
      "Channels scraped this run: 23\n",
      "UCoE9syjEjEPRMPQ08oF-QNA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 61\n",
      "Channels scraped this run: 24\n",
      "UCVARxGUVApmcn5OJ8tYvANA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 60\n",
      "Channels scraped this run: 25\n",
      "UCRpXE-_QtHDXBjWYoDNk9Hg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 59\n",
      "Channels scraped this run: 26\n",
      "UCr7VnJciYOa5DU30gWSXFyg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 58\n",
      "Channels scraped this run: 27\n",
      "UCjz6jY5XyWmp5LhsC17SCJw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 57\n",
      "Channels scraped this run: 28\n",
      "UCtfTukQiflH_dgBgtgV44Kg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 56\n",
      "Channels scraped this run: 29\n",
      "UCSW3d8G--3HPOc8pIYrAPtw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 55\n",
      "Channels scraped this run: 30\n",
      "UCHm1mqcoj9iP8xKoLL9klSg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 54\n",
      "Channels scraped this run: 31\n",
      "UC-p9YwJoYROFSKCypT0EprQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 53\n",
      "Channels scraped this run: 32\n",
      "UC4T-u4cAcQjjMVgcp39izoA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 52\n",
      "Channels scraped this run: 33\n",
      "UCPLIGv0eKdAlMb1e35Yrx1A\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 51\n",
      "Channels scraped this run: 34\n",
      "UC7lFUh7NTtrc6Jfj1FUfNOQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 50\n",
      "Channels scraped this run: 35\n",
      "UCF_sGOZ5b3ShD1ccrDvT7EA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 49\n",
      "Channels scraped this run: 36\n",
      "UCRVJmNdTSqPQqWcHvXEqiMA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 48\n",
      "Channels scraped this run: 37\n",
      "UCWDWoohWPjdyBA0Vr3U0Uhw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 47\n",
      "Channels scraped this run: 38\n",
      "UC8gFiTKS6FBHFVdsSNfONyQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 46\n",
      "Channels scraped this run: 39\n",
      "UCjL9oW0OQUc9o27j-HcDPyg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 45\n",
      "Channels scraped this run: 40\n",
      "UCG-C9SCY_zCXIIO5URA7Uiw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 44\n",
      "Channels scraped this run: 41\n",
      "UCYfAQboMvaW3fA2Q-foQVWQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 43\n",
      "Channels scraped this run: 42\n",
      "UCa9uXvUZKLbFgcwX19VD5sg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 42\n",
      "Channels scraped this run: 43\n",
      "UCXDzRMPwVmXEWPH3pXlxpoA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 41\n",
      "Channels scraped this run: 44\n",
      "UCkH_B7dxUYa9EySUgKxgmcA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 40\n",
      "Channels scraped this run: 45\n",
      "UCAv96UreVstQWQs8tWvQuog\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 39\n",
      "Channels scraped this run: 46\n",
      "UC7oPaJUFwmEbeW9DBvKUzxw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 38\n",
      "Channels scraped this run: 47\n",
      "UC4cyBbHOw0Esma1xK0ByE6A\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 37\n",
      "Channels scraped this run: 48\n",
      "UCihlJdqWzNCMCjVi9X1Df0w\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 36\n",
      "Channels scraped this run: 49\n",
      "UCQXU0th76ZN8M7uDUHF4SFQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 35\n",
      "Channels scraped this run: 50\n",
      "UC0pGVSvOmp-ILnOZC7N_3Gg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 34\n",
      "Channels scraped this run: 51\n",
      "UC0v9lRIC3RRIU-DYVWND6vw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 33\n",
      "Channels scraped this run: 52\n",
      "UCucffVgof7osguT77eSHmUQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 32\n",
      "Channels scraped this run: 53\n",
      "UC7xoQXLjVw0AlvX_IPOrqXA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 31\n",
      "Channels scraped this run: 54\n",
      "UCa9cpedPoo7y0vUdw96-aZw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 30\n",
      "Channels scraped this run: 55\n",
      "UCpAqxsrDwYsyOnMAPDfZe6w\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 29\n",
      "Channels scraped this run: 56\n",
      "UCvF-QTvseuT9ANqBKkKt18w\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 28\n",
      "Channels scraped this run: 57\n",
      "UCbjjMP52gLAw--HhLncZJrw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 27\n",
      "Channels scraped this run: 58\n",
      "UCSAbw9uQf9610zAdtnWkPAQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 26\n",
      "Channels scraped this run: 59\n",
      "UCKNdQaojdy31Ft76G7dq8pQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 25\n",
      "Channels scraped this run: 60\n",
      "UCtg_b1sjEr3-x9nHUgp03HA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 24\n",
      "Channels scraped this run: 61\n",
      "UCp743YRRQ3uK6lQ1mMt37Xw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 23\n",
      "Channels scraped this run: 62\n",
      "UC2eg8mOD_WVoVIytK-otr7w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________nothing happend________________\n",
      "channels to scrape remain: 22\n",
      "Channels scraped this run: 63\n",
      "UCnrjG0c2GqIx1kO1Tk6bqKQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 21\n",
      "Channels scraped this run: 64\n",
      "UCegkZYCHlmm1E1zP2mBE84g\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 20\n",
      "Channels scraped this run: 65\n",
      "UCGEHD0ymXQrVSvjWWPnAm0g\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 19\n",
      "Channels scraped this run: 66\n",
      "UCjO-9NVFO_TXLhecUO_nzMA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 18\n",
      "Channels scraped this run: 67\n",
      "UCuChDpbJEYi9s51RyVRXIPg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 17\n",
      "Channels scraped this run: 68\n",
      "UC67IQomN-xbTPlDfgCR7S8w\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 16\n",
      "Channels scraped this run: 69\n",
      "UC_HgJVDqISfB3GelkEVXneg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 15\n",
      "Channels scraped this run: 70\n",
      "UClivZMll3CZcEVgiEqhB-dg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 14\n",
      "Channels scraped this run: 71\n",
      "UCSb1s5RYEkLs729ZNAhAUZA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 13\n",
      "Channels scraped this run: 72\n",
      "UCI5lP66SNfNAZzuaaHduO1g\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 12\n",
      "Channels scraped this run: 73\n",
      "UCWKUciFnIsTNTTt_d-MGJZg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 11\n",
      "Channels scraped this run: 74\n",
      "UCwG1D-_Tepp8k36LhndE3JQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 10\n",
      "Channels scraped this run: 75\n",
      "UC6ffBs1bbmkBbCtxnZpUDjQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 9\n",
      "Channels scraped this run: 76\n",
      "UCAV2KzZmwpKOL6ZcmFv7tdQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 8\n",
      "Channels scraped this run: 77\n",
      "UCSzak3oSMADcMh6xOJLeaLw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 7\n",
      "Channels scraped this run: 78\n",
      "UCrHaLIj3_bC2pqkc4s9j2Yw\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 6\n",
      "Channels scraped this run: 79\n",
      "UCtrMSF_KvuoMkBrNqz01tzg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 5\n",
      "Channels scraped this run: 80\n",
      "UCSW3gpeK7wTa6Ov48X9ssqA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 4\n",
      "Channels scraped this run: 81\n",
      "UCUfc4zKoANtUUGuq31_EqRg\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 3\n",
      "Channels scraped this run: 82\n",
      "UCwCdTRWqXGbbfyWd0q0P-lQ\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 2\n",
      "Channels scraped this run: 83\n",
      "UCTG_LiNwNMPgP_T764fnhEA\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 1\n",
      "Channels scraped this run: 84\n",
      "UCmG9OupNTupsIqqde-H3E_g\n",
      "________________nothing happend________________\n",
      "channels to scrape remain: 0\n",
      "Channels scraped this run: 85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.372840944925944"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recive data using API and save it on PC\n",
    " \n",
    "API_KEY1 = \"AIzaSyCQHI5RSbHoKGh6sPPnnOyw**********\"\n",
    "\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "start = time.time()\n",
    "i=0\n",
    "while i < 4000 and len(channels_id) != 0:\n",
    "    for video in channels_id[:11000]:\n",
    "        i+=1\n",
    "        print(video)\n",
    "        yt = YTstats(API_KEY3, video)\n",
    "        yt.get_video_statistics()\n",
    "        yt.dump()\n",
    "        channels_id.remove(video)\n",
    "        print('channels to scrape remain:', f\"{len(channels_id):,}\")\n",
    "        print('Channels scraped this run:', f\"{i:,}\")\n",
    "        break\n",
    "end = time.time()\n",
    "(end-start)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc92e96",
   "metadata": {},
   "source": [
    "# read josn file and combine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32231271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read josn files and make a list with json files\n",
    "# (make 1 change)\n",
    "\n",
    "path_to_json = r'C:\\Users\\David\\Amber Heard Case\\Youtube\\Data\\channels info\\channels info for commenters - 5 batch 1'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "json_files;  \n",
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f099bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame with all json files:\n",
    "# (make 1 change)\n",
    "i=0\n",
    "df = pd.DataFrame()\n",
    "for file in json_files:\n",
    "    file_path = path_to_json + '/' + file\n",
    "    with open(file_path) as data_file:\n",
    "        i +=1\n",
    "        if i % 100 == 0: print(i)\n",
    "        data = json.load(data_file)\n",
    "        df = df.append(pd.json_normalize(data))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97731641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns.drop(list(df.filter(regex='localizations')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c1df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780d230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf82434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\David\\Amber Heard Case\\Youtube\\Data\\combined files for channels\\combined accounts info of commenters 5 batch 1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1935bd4",
   "metadata": {},
   "source": [
    "emails:\n",
    "\n",
    "some20738@gmail.com\n",
    "\n",
    "someeoonne6@gmail.com\n",
    "\n",
    "some65311@gmail.com\n",
    "\n",
    "ones40370@gmail.com\n",
    "\n",
    "soommeone3@gmail.com\n",
    "\n",
    "someo3315@gmail.com\n",
    "\n",
    "ones45977@gmail.com\n",
    "\n",
    "khairydavid32@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df192fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare files in a dir with a list then copy the target to the destination:\n",
    "start = time.time()\n",
    "path = r'C:\\Users\\David\\Amber Heard Case\\Youtube\\Data\\channels info\\channels info for commenters - 6 batch 1'\n",
    "source = os.listdir(path)\n",
    "destination = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info for commenters - 5\"\n",
    "\n",
    "i = 0            \n",
    "for file in source:\n",
    "    i+=1\n",
    "    if i % 500 == 0: print(i)\n",
    "    if file.split('.')[0] in channels_id_list_new:\n",
    "        shutil.copy(path + '/'+file, destination)\n",
    "end = time.time()\n",
    "print(\"time in minuts:\", (end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd28ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all json files in folder and subfolder:\n",
    "path_to_json = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info\\channels info for commenters - 16\"\n",
    "names = []\n",
    "for root, dirs, files in os.walk(path_to_json):\n",
    "    for name in files:\n",
    "        if name.endswith((\".json\")):\n",
    "            names.append(name.split('.')[0])\n",
    "            full_path = os.path.join(root, name)\n",
    "names = set(names)\n",
    "names = list(names)\n",
    "print('Count of channels we have info for: ', f\"{len(names):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
