{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8698aa33",
   "metadata": {},
   "source": [
    "# read and combining JSONs of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1572e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from csv import reader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9497293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read josn files and make a list with json files\n",
    "\n",
    "folder_no = 2\n",
    "path_to_json = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2018\\{}\".format(folder_no)\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "json_files;  \n",
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ebf8f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 (500, 45) folder no: 2\n",
      "1000 (1000, 50) folder no: 2\n",
      "1500 (1500, 50) folder no: 2\n",
      "2000 (2000, 51) folder no: 2\n",
      "2500 (2500, 57) folder no: 2\n",
      "3000 (3000, 58) folder no: 2\n",
      "3500 (3500, 71) folder no: 2\n",
      "4000 (4000, 77) folder no: 2\n",
      "4500 (4500, 78) folder no: 2\n",
      "5000 (5000, 82) folder no: 2\n",
      "5500 (5500, 82) folder no: 2\n",
      "6000 (6000, 82) folder no: 2\n",
      "6500 (6500, 82) folder no: 2\n",
      "7000 (7000, 82) folder no: 2\n",
      "7500 (7500, 82) folder no: 2\n",
      "8000 (8000, 82) folder no: 2\n",
      "8500 (8500, 82) folder no: 2\n",
      "9000 (9000, 83) folder no: 2\n",
      "9500 (9500, 83) folder no: 2\n",
      "10000 (10000, 207) folder no: 2\n",
      "10500 (10500, 207) folder no: 2\n",
      "11000 (11000, 207) folder no: 2\n",
      "11500 (11500, 207) folder no: 2\n",
      "12000 (12000, 207) folder no: 2\n",
      "12500 (12500, 207) folder no: 2\n",
      "13000 (13000, 207) folder no: 2\n",
      "13500 (13500, 207) folder no: 2\n",
      "14000 (14000, 207) folder no: 2\n",
      "14500 (14500, 207) folder no: 2\n",
      "15000 (15000, 207) folder no: 2\n",
      "15500 (15500, 207) folder no: 2\n",
      "16000 (16000, 207) folder no: 2\n",
      "16500 (16500, 207) folder no: 2\n",
      "17000 (17000, 207) folder no: 2\n",
      "17500 (17500, 207) folder no: 2\n",
      "18000 (18000, 207) folder no: 2\n",
      "18500 (18500, 207) folder no: 2\n",
      "19000 (19000, 207) folder no: 2\n",
      "19500 (19500, 207) folder no: 2\n",
      "20000 (20000, 207) folder no: 2\n",
      "20500 (20500, 207) folder no: 2\n",
      "21000 (21000, 207) folder no: 2\n",
      "21500 (21500, 207) folder no: 2\n",
      "22000 (22000, 207) folder no: 2\n",
      "22500 (22500, 207) folder no: 2\n",
      "23000 (23000, 207) folder no: 2\n",
      "23500 (23500, 207) folder no: 2\n",
      "24000 (24000, 207) folder no: 2\n",
      "24500 (24500, 207) folder no: 2\n",
      "25000 (25000, 207) folder no: 2\n",
      "25500 (25500, 207) folder no: 2\n",
      "26000 (26000, 207) folder no: 2\n",
      "26500 (26500, 207) folder no: 2\n",
      "27000 (27000, 207) folder no: 2\n",
      "27500 (27500, 207) folder no: 2\n",
      "28000 (28000, 207) folder no: 2\n",
      "28500 (28500, 207) folder no: 2\n",
      "29000 (29000, 207) folder no: 2\n",
      "29500 (29500, 207) folder no: 2\n",
      "30000 (30000, 207) folder no: 2\n",
      "elapsed time: 48.96722044547399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 207)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame with all json files:\n",
    "df = pd.DataFrame()\n",
    "start = time.time()\n",
    "i=0\n",
    "for file in json_files:\n",
    "    file_path = path_to_json + '/' + file\n",
    "    with open(file_path) as data_file:\n",
    "        i +=1\n",
    "        data = json.load(data_file)\n",
    "        df = df.append(pd.json_normalize(data))\n",
    "        if i % 500 == 0: print(i, df.shape, \"folder no:\", folder_no)\n",
    "end = time.time()\n",
    "print('elapsed time:',(end-start)/60)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e287dc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kind', 'etag', 'id', 'snippet.title', 'snippet.description',\n",
       "       'snippet.publishedAt', 'snippet.thumbnails.default.url',\n",
       "       'snippet.thumbnails.default.width', 'snippet.thumbnails.default.height',\n",
       "       'snippet.thumbnails.medium.url',\n",
       "       ...\n",
       "       'localizations.sr_Latn_RS.title',\n",
       "       'localizations.sr_Latn_RS.description', 'localizations.da_DK.title',\n",
       "       'localizations.da_DK.description', 'localizations.sw_TZ.title',\n",
       "       'localizations.sw_TZ.description', 'localizations.bg_BG.title',\n",
       "       'localizations.bg_BG.description', 'localizations.nb_NO.title',\n",
       "       'localizations.nb_NO.description'],\n",
       "      dtype='object', length=207)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7e5e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns.drop(list(df.filter(regex='localizations')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a83809c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 41)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d6ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2018\\folder {}.csv\".format(folder_no), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e574d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571fe04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "790a746b",
   "metadata": {},
   "source": [
    "2021 have 346,486 channel ID\n",
    "\n",
    "2020 have 450,538 channel ID\n",
    "\n",
    "2019 have 81,358 channel ID\n",
    "\n",
    "2018 have 134,940 channel ID\n",
    "\n",
    "2017 have 32,756 channel ID\n",
    "\n",
    "2016 have 37,904 channel ID\n",
    "\n",
    "2015 have 20,537 channel ID\n",
    "\n",
    "2014 have 36,833 channel ID\n",
    "\n",
    "2008 to 2013 have 12,480 channel ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42d46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
