{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8357d18",
   "metadata": {},
   "source": [
    "# Read channle IDs then search on it on json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from csv import reader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54495266",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "url = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\combinded for comments (filtered)\\comments filter by year(based on comment year Not main video)\\comments_data_{}.csv\".format(year)\n",
    "\n",
    "\n",
    "channels_ids = pd.read_csv(url, usecols=['snippet.topLevelComment.snippet.authorChannelId.value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_ids = list(channels_ids['snippet.topLevelComment.snippet.authorChannelId.value'])\n",
    "channels_ids = set(channels_ids)\n",
    "channels_ids = list(channels_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cd7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(channels_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76c491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare files in a dir with a list then copy the target to the destination:\n",
    "\n",
    "for ii in range(1, 25):\n",
    "    \n",
    "\n",
    "    start = time.time()\n",
    "    path = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info\\channels info for commenters - {}\".format(ii)\n",
    "    source = os.listdir(path)\n",
    "    destination = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\{}\\{}\".format(year, ii)\n",
    "\n",
    "    i = 0            \n",
    "    for file in source:\n",
    "        i+=1\n",
    "        if i % 500 == 0: print('file no:', i, 'in folder',ii)\n",
    "        if file.split('.')[0] in channels_ids:\n",
    "            shutil.copy(path + '/'+file, destination)\n",
    "            channels_ids.remove(file.split('.')[0])\n",
    "    end = time.time()\n",
    "    print(\"time in minuts:\", (end - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd6d5c",
   "metadata": {},
   "source": [
    "# See if IDs not obtainied data for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6a659f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of channels we have info for:  81,310\n"
     ]
    }
   ],
   "source": [
    "# read all json files in folder and subfolder:\n",
    "path_to_json = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2019\"\n",
    "names = []\n",
    "for root, dirs, files in os.walk(path_to_json):\n",
    "    for name in files:\n",
    "        if name.endswith((\".json\")):\n",
    "            names.append(name.split('.')[0])\n",
    "            full_path = os.path.join(root, name)\n",
    "names = set(names)\n",
    "names = list(names)\n",
    "print('Count of channels we have info for: ', f\"{len(names):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a9ce22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162668"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = channels_ids + names\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c3ce6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = pd.DataFrame(all_ids, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5aaab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = all_ids.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33d7b837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd379aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids.to_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\2019_channels_ids.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87de79",
   "metadata": {},
   "source": [
    "# Reading JSON files and combine them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a97e391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read josn files and make a list with json files\n",
    "\n",
    "folder_no = 1\n",
    "path_to_json = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2019\\{}\".format(folder_no)\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "json_files;  \n",
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28309b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame with all json files:\n",
    "df = pd.DataFrame()\n",
    "start = time.time()\n",
    "i=0\n",
    "for file in json_files:\n",
    "    file_path = path_to_json + '/' + file\n",
    "    with open(file_path) as data_file:\n",
    "        i +=1\n",
    "        data = json.load(data_file)\n",
    "        df = df.append(pd.json_normalize(data))\n",
    "        if i % 500 == 0: print(i, df.shape, \"folder no:\", folder_no)\n",
    "end = time.time()\n",
    "print('elapsed time:',(end-start)/60)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9366795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns.drop(list(df.filter(regex='localizations')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2019\\folder {}.csv\".format(folder_no), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46b490",
   "metadata": {},
   "source": [
    "# Read combined files for each folder and make 1 CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c39316a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read josn files and make a list with json files\n",
    "# (make 1 change)\n",
    "\n",
    "path_to_csv = r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2019\"\n",
    "csv_files = [pos_csv for pos_csv in os.listdir(path_to_csv) if pos_csv.endswith('.csv')]\n",
    "csv_files;  \n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfaa623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81310, 41)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in csv_files:\n",
    "    temp_df = pd.read_csv(path_to_csv + '/' + file)\n",
    "    df = df.append(temp_df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0efc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\David\\Amber Heard Case\\Youtube\\New Data (filtered with 'amber' word)\\channels info by years\\2019\\channles_info_2019.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec12ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
